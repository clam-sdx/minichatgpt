{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61c92b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffbc2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from minichatgpt.experiments.imdb import config, sent_kwargs\n",
    "from minichatgpt import PPOTrainer, Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b0b43bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the sake of the speed of this demonstration, the batch_size is temporarily decreased from 256 to 4\n",
    "batch_size = 4\n",
    "config.batch_size = batch_size\n",
    "config.forward_batch_size = batch_size//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46e2af09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/carson/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
      "Loading cached processed dataset at /Users/carson/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-2bd6a5d7d39a840d.arrow\n",
      "Loading cached processed dataset at /Users/carson/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-2ecf25d24c93f132.arrow\n"
     ]
    }
   ],
   "source": [
    "lab = Lab(config)\n",
    "dataset = lab.build_dataset(dataset_name=\"imdb\",input_min_text_length=2,input_max_text_length=8)\n",
    "new_policy, old_policy, tokenizer = lab.init_policies_tokenizer()\n",
    "lab.set_generation_config(do_sample=True,output_min_length=4,output_max_length=16,pad_token_id=tokenizer.eos_token_id)\n",
    "ppo_trainer = lab.init_ppo_trainer(config, new_policy, old_policy, tokenizer, dataset)\n",
    "reward_model = lab.init_reward_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec4d1f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(-0.9046), tensor(1.5498), tensor(0.3456), tensor(2.5015)]\n"
     ]
    }
   ],
   "source": [
    "for batch_step, batch in enumerate(ppo_trainer.dataloader):\n",
    "    \n",
    "    queries = batch['input_ids']\n",
    "    \n",
    "    #### Get response from gpt2\n",
    "    responses = []\n",
    "    for query in queries:\n",
    "        gen_len = lab.output_length_sampler()\n",
    "        lab.generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "        response = ppo_trainer.generate(query, **lab.generation_kwargs)\n",
    "        responses.append(response.squeeze()[-gen_len:])\n",
    "\n",
    "    batch['response'] = [tokenizer.decode(r.squeeze()) for r in responses]\n",
    "\n",
    "    #### Compute sentiment score\n",
    "    texts = [q + r for q,r in zip(batch['query'], batch['response'])]\n",
    "    pipe_outputs = lab.reward_model(texts, **sent_kwargs)\n",
    "    rewards = [torch.tensor(output[1][\"score\"]) for output in pipe_outputs]\n",
    "    break\n",
    "    \n",
    "print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d37e509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([-0.0000, -0.0000, -0.0000, -0.0000, -0.9046]), tensor([-0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "        1.5498]), tensor([-0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "        -0.0000, 0.3456]), tensor([-0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "        -0.0000, 2.5015])]\n"
     ]
    }
   ],
   "source": [
    "queries, responses, scores = ppo_trainer._step_safety_checker(batch_size, queries, responses, rewards)\n",
    "logprobs, ref_logprobs, values = ppo_trainer.batched_forward_pass(queries, responses)\n",
    "rewards, non_score_reward = ppo_trainer.compute_rewards(scores, logprobs, ref_logprobs)\n",
    "print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dae14343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss/policy': tensor(-2.3842e-08, grad_fn=<MeanBackward0>),\n",
       " 'loss/value': tensor(2.1323, grad_fn=<MulBackward0>),\n",
       " 'loss/total': tensor(0.2132, grad_fn=<AddBackward0>),\n",
       " 'policy/entropy': tensor(4.6713, grad_fn=<MeanBackward0>),\n",
       " 'policy/approxkl': tensor(0., grad_fn=<MulBackward0>),\n",
       " 'policy/policykl': tensor(0., grad_fn=<MeanBackward0>),\n",
       " 'policy/clipfrac': tensor(0., dtype=torch.float64),\n",
       " 'policy/advantages': tensor([[ 0.5925,  0.4375,  1.0873, -1.1887, -0.9287]]),\n",
       " 'policy/advantages_mean': tensor(2.3842e-08),\n",
       " 'policy/ratio': tensor([[1., 1., 1., 1., 1.]], grad_fn=<ExpBackward0>),\n",
       " 'returns/mean': tensor(-0.8628),\n",
       " 'returns/var': tensor(0.0058),\n",
       " 'val/vpred': tensor(-2.5561, grad_fn=<MeanBackward0>),\n",
       " 'val/error': tensor(3.2110, grad_fn=<MeanBackward0>),\n",
       " 'val/clipfrac': tensor(0.4000, dtype=torch.float64),\n",
       " 'val/mean': tensor(-1.3650),\n",
       " 'val/var': tensor(3.8172),\n",
       " 'time/ppo/optimizer_step': tensor([1.1034])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = list(range(config.batch_size))\n",
    "\n",
    "for idx in range(config.batch_size):\n",
    "\n",
    "    train_stats = ppo_trainer.train_minibatch(\n",
    "        logprobs[idx].unsqueeze(0),\n",
    "        values[idx].unsqueeze(0),\n",
    "        rewards[idx].unsqueeze(0),\n",
    "        queries[idx].unsqueeze(0),\n",
    "        responses[idx].unsqueeze(0),\n",
    "        torch.cat([queries[idx], responses[idx]]).unsqueeze(0),\n",
    "    )\n",
    "    \n",
    "    break\n",
    "    \n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75160123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_trainer.config.ppo_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a769d7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
